{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 08:19:33.413061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 08:19:33.413105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 08:19:33.462483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-14 08:19:33.563074: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 08:19:34.266486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lorfs.csv\n",
    "lorfs_short = pd.read_csv('Data/Test/lorfs_short.csv')\n",
    "lorfs_medium = pd.read_csv('Data/Test/lorfs_medium.csv')\n",
    "lorfs_long = pd.read_csv('Data/Test/lorfs_long.csv')\n",
    "\n",
    "# sort by length\n",
    "lorfs_short = lorfs_short.sort_values(by='length')\n",
    "lorfs_medium = lorfs_medium.sort_values(by='length')\n",
    "lorfs_long = lorfs_long.sort_values(by='length')\n",
    "\n",
    "def filter_non_aa(df):\n",
    "    non_amino_acids = ['\\*','x','0','1',';','5','4','7','8','9','>','_','\\.','2','\\-','3','6']\n",
    "    pattern = '|'.join(non_amino_acids)\n",
    "\n",
    "    print(\"Original shape:\", df.shape)\n",
    "    orginal_shape = df.shape\n",
    "    # Make sure the sequence column doesn't contain any of these characters\n",
    "    df = df[~df['Sequence'].str.contains(pattern, regex=True, case=False, na=False)]\n",
    "    # Print new shape\n",
    "    print(\"New shape after filtering:\", df.shape)\n",
    "    print(\"Number of removed rows:\", orginal_shape[0] - df.shape[0])\n",
    "    print(\"\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode_sequences(df, padding_length):\n",
    "    df = filter_non_aa(df)\n",
    "    tokenizer = Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(df['Sequence'])\n",
    "    sequences_numeric = tokenizer.texts_to_sequences(df['Sequence'])\n",
    "    sequences_padded = pad_sequences(sequences_numeric, maxlen=padding_length, padding='post', truncating='post')\n",
    "    one_hot_sequences = np.zeros((len(sequences_padded), padding_length, (len(tokenizer.word_index) + 1)))\n",
    "    for i, sequence in enumerate(sequences_padded):\n",
    "        for j, char_index in enumerate(sequence):\n",
    "            if char_index != 0:  # Skip padding\n",
    "                one_hot_sequences[i, j, char_index] = 1\n",
    "    one_hot_sequences = one_hot_sequences[:,:,1:]\n",
    "    return one_hot_sequences, df['has_hmm'], pd.DataFrame(df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (25635, 5)\n",
      "New shape after filtering: (25634, 5)\n",
      "Number of removed rows: 1\n",
      "\n",
      "\n",
      "Original shape: (4680, 5)\n",
      "New shape after filtering: (4680, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (711, 5)\n",
      "New shape after filtering: (711, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (27960, 5)\n",
      "New shape after filtering: (27959, 5)\n",
      "Number of removed rows: 1\n",
      "\n",
      "\n",
      "Original shape: (3405, 5)\n",
      "New shape after filtering: (3405, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (762, 5)\n",
      "New shape after filtering: (762, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (29928, 5)\n",
      "New shape after filtering: (29928, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (5750, 5)\n",
      "New shape after filtering: (5750, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (779, 5)\n",
      "New shape after filtering: (779, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (13879, 5)\n",
      "New shape after filtering: (13878, 5)\n",
      "Number of removed rows: 1\n",
      "\n",
      "\n",
      "Original shape: (1605, 5)\n",
      "New shape after filtering: (1605, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (441, 5)\n",
      "New shape after filtering: (441, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (35480, 5)\n",
      "New shape after filtering: (35478, 5)\n",
      "Number of removed rows: 2\n",
      "\n",
      "\n",
      "Original shape: (20745, 5)\n",
      "New shape after filtering: (20745, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n",
      "Original shape: (4635, 5)\n",
      "New shape after filtering: (4635, 5)\n",
      "Number of removed rows: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folders = ['Nitrosomonas_europaea', 'Nitrosomonas_ureae', 'Nitrosospira_briensis', 'Candidatus_Methylopumilus_turicensis', 'Aquincola_tertiaricarbonis']  # Adjust as necessary\n",
    "\n",
    "# Dictionaries to store processed data\n",
    "processed_data = {\n",
    "    'short': {},\n",
    "    'medium': {},\n",
    "    'long': {}\n",
    "}\n",
    "\n",
    "for folder in folders:\n",
    "    lorfs_short_path = f'Data/Test/{folder}/lorfs_short.csv'\n",
    "    lorfs_medium_path = f'Data/Test/{folder}/lorfs_medium.csv'\n",
    "    lorfs_long_path = f'Data/Test/{folder}/lorfs_long.csv'\n",
    "    \n",
    "    lorfs_short = pd.read_csv(lorfs_short_path).sort_values(by='length')\n",
    "    lorfs_medium = pd.read_csv(lorfs_medium_path).sort_values(by='length')\n",
    "    lorfs_long = pd.read_csv(lorfs_long_path).sort_values(by='length')\n",
    "    \n",
    "    processed_short = one_hot_encode_sequences(lorfs_short, 100)\n",
    "    processed_medium = one_hot_encode_sequences(lorfs_medium, 400)\n",
    "    processed_long = one_hot_encode_sequences(lorfs_long, 1000)\n",
    "    \n",
    "    processed_data['short'][folder] = processed_short\n",
    "    processed_data['medium'][folder] = processed_medium\n",
    "    processed_data['long'][folder] = processed_long\n",
    "\n",
    "# Now `processed_data` contains all the processed data indexed by length category and folder name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_and_evaluate(models, data, targets):\n",
    "    \"\"\"\n",
    "    Predicts outcomes using the given models and evaluates their accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "    - models: A dictionary of loaded models keyed by dataset size ('short', 'medium', 'long').\n",
    "    - data: A dictionary containing the preprocessed input data for each model, keyed by dataset size.\n",
    "    - targets: A dictionary containing the true labels for each dataset size.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing the accuracy scores keyed by dataset size.\n",
    "    \"\"\"\n",
    "    accuracies = {}\n",
    "    \n",
    "    for size in models.keys():\n",
    "        # Make predictions\n",
    "        predictions = models[size].predict(data[size])\n",
    "        \n",
    "        # Convert predictions to binary\n",
    "        binary_predictions = [1 if i > 0.5 else 0 for i in predictions.ravel()]\n",
    "        \n",
    "        # Calculate and store accuracy\n",
    "        accuracy = accuracy_score(targets[size], binary_predictions)\n",
    "        accuracies[size] = accuracy\n",
    "        print(f'{size.capitalize()} dataset accuracy: {accuracy}')\n",
    "        # confusion matrix\n",
    "        print(f'{size.capitalize()} dataset confusion matrix:')\n",
    "        print(confusion_matrix(targets[size], binary_predictions))\n",
    "        print('\\n')\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Example of how to use the function\n",
    "# Assuming lorfs_short_one_hot_flat, lorfs_medium_one_hot_flat, lorfs_long_one_hot_flat, \n",
    "# lorfs_short_target, lorfs_medium_target, lorfs_long_target are defined\n",
    "\n",
    "data = {\n",
    "    'short': lorfs_short_one_hot_flat,\n",
    "    'medium': lorfs_medium_one_hot_flat,\n",
    "    'long': lorfs_long_one_hot_flat\n",
    "}\n",
    "\n",
    "targets = {\n",
    "    'short': lorfs_short_target,\n",
    "    'medium': lorfs_medium_target,\n",
    "    'long': lorfs_long_target\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to predict and evaluate using the processed_data dictionary\n",
    "def predict_and_evaluate_with_processed_data(models, processed_data, flat = 1):\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for size in ['short', 'medium', 'long']:\n",
    "        size_results = {}\n",
    "        for folder in processed_data[size]:\n",
    "            data, targets, _ = processed_data[size][folder]  # Assuming this structure\n",
    "            if flat:\n",
    "                data_flat = data.reshape(data.shape[0], -1)\n",
    "            else:\n",
    "                data_flat = data\n",
    "            \n",
    "            predictions = models[size].predict(data_flat)\n",
    "            binary_predictions = [1 if i > 0.5 else 0 for i in predictions.ravel()]\n",
    "            \n",
    "            accuracy = accuracy_score(targets, binary_predictions)\n",
    "            confusion_mat = confusion_matrix(targets, binary_predictions)\n",
    "            \n",
    "            size_results[folder] = {'accuracy': accuracy, 'confusion_matrix': confusion_mat}\n",
    "        \n",
    "        evaluation_results[size] = size_results\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "def print_summary(all_accuracies):\n",
    "    for size, results in all_accuracies.items():\n",
    "        print(f\"--- {size.upper()} DATASET RESULTS ---\")\n",
    "        for folder, metrics in results.items():\n",
    "            print(f\"Folder: {folder}\")\n",
    "            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(metrics['confusion_matrix'])\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 08:21:04.229392: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 08:21:04.416462: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SHORT DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.5765\n",
      "Confusion Matrix:\n",
      "[[13371 10165]\n",
      " [  692  1406]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.6067\n",
      "Confusion Matrix:\n",
      "[[15573  9944]\n",
      " [ 1052  1390]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.5658\n",
      "Confusion Matrix:\n",
      "[[15467 12178]\n",
      " [  818  1465]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.6204\n",
      "Confusion Matrix:\n",
      "[[7946 4719]\n",
      " [ 549  664]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.5749\n",
      "Confusion Matrix:\n",
      "[[19058 14126]\n",
      " [  957  1337]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- MEDIUM DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.4737\n",
      "Confusion Matrix:\n",
      "[[1241 1385]\n",
      " [1078  976]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.7941\n",
      "Confusion Matrix:\n",
      "[[1123  207]\n",
      " [ 494 1581]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.7165\n",
      "Confusion Matrix:\n",
      "[[2814  834]\n",
      " [ 796 1306]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.6922\n",
      "Confusion Matrix:\n",
      "[[267 181]\n",
      " [313 844]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.6028\n",
      "Confusion Matrix:\n",
      "[[9708 6092]\n",
      " [2148 2797]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- LONG DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.8228\n",
      "Confusion Matrix:\n",
      "[[  7  17]\n",
      " [109 578]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.7874\n",
      "Confusion Matrix:\n",
      "[[ 11  20]\n",
      " [142 589]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.7946\n",
      "Confusion Matrix:\n",
      "[[  9  18]\n",
      " [142 610]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.8163\n",
      "Confusion Matrix:\n",
      "[[  1   2]\n",
      " [ 79 359]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.6990\n",
      "Confusion Matrix:\n",
      "[[1145 1031]\n",
      " [ 364 2095]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the loaded models\n",
    "base_dir = 'Models/Dense'\n",
    "dataset_sizes = ['short', 'medium', 'long']\n",
    "models = {}\n",
    "\n",
    "# Loop through the dataset sizes, load each model, and add it to the dictionary\n",
    "for size in dataset_sizes:\n",
    "    model_name = f'{size}_dataset_model.keras'\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    models[size] = load_model(model_path)\n",
    "# Call the evaluation function with the loaded models and the processed_data dictionary\n",
    "all_accuracies = predict_and_evaluate_with_processed_data(models, processed_data)\n",
    "\n",
    "print_summary(all_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SHORT DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.6209\n",
      "Confusion Matrix:\n",
      "[[14632  8904]\n",
      " [  813  1285]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.6507\n",
      "Confusion Matrix:\n",
      "[[16994  8523]\n",
      " [ 1244  1198]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.6389\n",
      "Confusion Matrix:\n",
      "[[17822  9823]\n",
      " [  985  1298]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.6698\n",
      "Confusion Matrix:\n",
      "[[8695 3970]\n",
      " [ 612  601]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.6460\n",
      "Confusion Matrix:\n",
      "[[21787 11397]\n",
      " [ 1162  1132]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- MEDIUM DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.5415\n",
      "Confusion Matrix:\n",
      "[[2302  324]\n",
      " [1822  232]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.4628\n",
      "Confusion Matrix:\n",
      "[[1246   84]\n",
      " [1745  330]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.5979\n",
      "Confusion Matrix:\n",
      "[[3293  355]\n",
      " [1957  145]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.2841\n",
      "Confusion Matrix:\n",
      "[[ 448    0]\n",
      " [1149    8]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.7375\n",
      "Confusion Matrix:\n",
      "[[15058   742]\n",
      " [ 4703   242]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- LONG DATASET RESULTS ---\n",
      "Folder: Nitrosomonas_europaea\n",
      "Accuracy: 0.5387\n",
      "Confusion Matrix:\n",
      "[[ 14  10]\n",
      " [318 369]]\n",
      "\n",
      "\n",
      "Folder: Nitrosomonas_ureae\n",
      "Accuracy: 0.6024\n",
      "Confusion Matrix:\n",
      "[[ 12  19]\n",
      " [284 447]]\n",
      "\n",
      "\n",
      "Folder: Nitrosospira_briensis\n",
      "Accuracy: 0.4403\n",
      "Confusion Matrix:\n",
      "[[ 11  16]\n",
      " [420 332]]\n",
      "\n",
      "\n",
      "Folder: Candidatus_Methylopumilus_turicensis\n",
      "Accuracy: 0.3968\n",
      "Confusion Matrix:\n",
      "[[  3   0]\n",
      " [266 172]]\n",
      "\n",
      "\n",
      "Folder: Aquincola_tertiaricarbonis\n",
      "Accuracy: 0.6209\n",
      "Confusion Matrix:\n",
      "[[2094   82]\n",
      " [1675  784]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the loaded models\n",
    "base_dir = 'Models/RNN'\n",
    "dataset_sizes = ['short', 'medium', 'long']\n",
    "models = {}\n",
    "\n",
    "# Loop through the dataset sizes, load each model, and add it to the dictionary\n",
    "for size in dataset_sizes:\n",
    "    model_name = f'{size}_dataset_model.keras'\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    models[size] = load_model(model_path)\n",
    "# Call the evaluation function with the loaded models and the processed_data dictionary\n",
    "all_accuracies = predict_and_evaluate_with_processed_data(models, processed_data, flat = 0)\n",
    "\n",
    "print_summary(all_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

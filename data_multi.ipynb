{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62728/3330935083.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-07 01:55:38.248798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-07 01:55:38.248822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-07 01:55:38.249352: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-07 01:55:38.252839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-07 01:55:38.702411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>length</th>\n",
       "      <th>genome_id</th>\n",
       "      <th>has_hmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC_010085.1;1000047;1000160;+</td>\n",
       "      <td>MSANMGLSIEGIPSFGGPPPLILSKGIRCLMPSVSII</td>\n",
       "      <td>37</td>\n",
       "      <td>GCF_000018465.1_ASM1846v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC_010085.1;1000357;1000449;+</td>\n",
       "      <td>MDRIWTNPFNDFSKARINEYRSNPKGKCIT</td>\n",
       "      <td>30</td>\n",
       "      <td>GCF_000018465.1_ASM1846v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC_010085.1;1000687;1000782;+</td>\n",
       "      <td>MGKWIFCFQRRMGMGFSNASCNTCNHSSRAR</td>\n",
       "      <td>31</td>\n",
       "      <td>GCF_000018465.1_ASM1846v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC_010085.1;1000385;1000831;+</td>\n",
       "      <td>MIFQRPESMNTEATLKGNVLHDITHWGISASIGVTFIVHSIKKFDP...</td>\n",
       "      <td>148</td>\n",
       "      <td>GCF_000018465.1_ASM1846v1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC_010085.1;1000860;1001009;+</td>\n",
       "      <td>MNFFIFGFGITAPHALSCPPPEPPRSVANKLTILPKCTLQFLEPLTDTA</td>\n",
       "      <td>49</td>\n",
       "      <td>GCF_000018465.1_ASM1846v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header  \\\n",
       "0  NC_010085.1;1000047;1000160;+   \n",
       "1  NC_010085.1;1000357;1000449;+   \n",
       "2  NC_010085.1;1000687;1000782;+   \n",
       "3  NC_010085.1;1000385;1000831;+   \n",
       "4  NC_010085.1;1000860;1001009;+   \n",
       "\n",
       "                                            Sequence  length  \\\n",
       "0              MSANMGLSIEGIPSFGGPPPLILSKGIRCLMPSVSII      37   \n",
       "1                     MDRIWTNPFNDFSKARINEYRSNPKGKCIT      30   \n",
       "2                    MGKWIFCFQRRMGMGFSNASCNTCNHSSRAR      31   \n",
       "3  MIFQRPESMNTEATLKGNVLHDITHWGISASIGVTFIVHSIKKFDP...     148   \n",
       "4  MNFFIFGFGITAPHALSCPPPEPPRSVANKLTILPKCTLQFLEPLTDTA      49   \n",
       "\n",
       "                   genome_id  has_hmm  \n",
       "0  GCF_000018465.1_ASM1846v1        0  \n",
       "1  GCF_000018465.1_ASM1846v1        0  \n",
       "2  GCF_000018465.1_ASM1846v1        0  \n",
       "3  GCF_000018465.1_ASM1846v1        1  \n",
       "4  GCF_000018465.1_ASM1846v1        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/lorfs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 100\n",
    "high = 400\n",
    "# divide df into 3 dfs based on \"lenght\"\n",
    "df1 = df[df['length'] < low]\n",
    "df2 = df[(df['length'] >= low) & (df['length'] < high)]\n",
    "df3 = df[df['length'] >= high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF1:\n",
      "Before undersampling: 2146532 rows, 7.65% minority class\n",
      "After undersampling: 328462 rows, 50.00% minority class\n",
      "\n",
      "DF2:\n",
      "Before undersampling: 531987 rows, 35.47% minority class\n",
      "After undersampling: 377392 rows, 50.00% minority class\n",
      "\n",
      "DF3:\n",
      "Before undersampling: 106544 rows, 76.83% minority class\n",
      "After undersampling: 49370 rows, 50.00% minority class\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to undersample a dataframe and print details\n",
    "def undersample_dataframe(df, column_name='has_hmm'):\n",
    "    # Print initial stats\n",
    "    initial_total = len(df)\n",
    "    initial_percentage_minority = df[column_name].mean() * 100\n",
    "    print(f\"Before undersampling: {initial_total} rows, {initial_percentage_minority:.2f}% minority class\")\n",
    "\n",
    "    # Separate the majority and minority classes\n",
    "    minority_class_size = df[column_name].value_counts().min()\n",
    "    majority_class_size = df[column_name].value_counts().max()\n",
    "\n",
    "    # Identify the majority and minority class labels\n",
    "    majority_class_label = df[column_name].value_counts().idxmax()\n",
    "    minority_class_label = df[column_name].value_counts().idxmin()\n",
    "\n",
    "    # Split the dataframe into majority and minority\n",
    "    df_majority = df[df[column_name] == majority_class_label]\n",
    "    df_minority = df[df[column_name] == minority_class_label]\n",
    "\n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = df_majority.sample(n=minority_class_size, random_state=42)  # Random state for reproducibility\n",
    "\n",
    "    # Combine minority class with downsampled majority class\n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    # Print final stats\n",
    "    final_total = len(df_balanced)\n",
    "    final_percentage_minority = df_balanced[column_name].mean() * 100\n",
    "    print(f\"After undersampling: {final_total} rows, {final_percentage_minority:.2f}% minority class\")\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "# Example usage with df1, assuming 'has_hmm' is the column of interest\n",
    "print(\"DF1:\")\n",
    "df1 = undersample_dataframe(df1, 'has_hmm')\n",
    "print(\"\\nDF2:\")\n",
    "df2 = undersample_dataframe(df2, 'has_hmm')\n",
    "print(\"\\nDF3:\")\n",
    "df3 = undersample_dataframe(df3, 'has_hmm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the samples with unclear amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (328462, 5)\n",
      "New shape after filtering: (328460, 5)\n",
      "Number of removed rows: 2\n",
      "\n",
      "\n",
      "Original shape: (377392, 5)\n",
      "New shape after filtering: (377379, 5)\n",
      "Number of removed rows: 13\n",
      "\n",
      "\n",
      "Original shape: (49370, 5)\n",
      "New shape after filtering: (49362, 5)\n",
      "Number of removed rows: 8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_non_aa(df):\n",
    "    non_amino_acids = ['\\*','x','0','1',';','5','4','7','8','9','>','_','\\.','2','\\-','3','6']\n",
    "    pattern = '|'.join(non_amino_acids)\n",
    "\n",
    "    print(\"Original shape:\", df.shape)\n",
    "    orginal_shape = df.shape\n",
    "    # Make sure the sequence column doesn't contain any of these characters\n",
    "    df = df[~df['Sequence'].str.contains(pattern, regex=True, case=False, na=False)]\n",
    "    # Print new shape\n",
    "    print(\"New shape after filtering:\", df.shape)\n",
    "    print(\"Number of removed rows:\", orginal_shape[0] - df.shape[0])\n",
    "    print(\"\\n\")\n",
    "    return df\n",
    "\n",
    "df1 = filter_non_aa(df1)\n",
    "df2 = filter_non_aa(df2)\n",
    "df3 = filter_non_aa(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode_sequences(df, padding_length, name):\n",
    "    tokenizer = Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(df['Sequence'])\n",
    "    sequences_numeric = tokenizer.texts_to_sequences(df['Sequence'])\n",
    "    sequences_padded = pad_sequences(sequences_numeric, maxlen=padding_length, padding='post', truncating='post')\n",
    "    one_hot_sequences = np.zeros((len(sequences_padded), padding_length, (len(tokenizer.word_index) + 1)))\n",
    "    for i, sequence in enumerate(sequences_padded):\n",
    "        for j, char_index in enumerate(sequence):\n",
    "            if char_index != 0:  # Skip padding\n",
    "                one_hot_sequences[i, j, char_index] = 1\n",
    "    one_hot_sequences = one_hot_sequences[:,:,1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(one_hot_sequences, df['has_hmm'], test_size=0.2)\n",
    "    np.savez_compressed('Data/' + name + '.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "    np.savez_compressed('Data/' + name + '_meta.npz', name = df['genome_id'], length = df['length'], target = df['has_hmm'])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encode_sequences(df1, 100, 'lorfs_100')\n",
    "one_hot_encode_sequences(df2, 400, 'lorfs_400')\n",
    "one_hot_encode_sequences(df3, 1000, 'lorfs_1000')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
